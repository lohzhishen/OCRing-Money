{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92aef08a",
   "metadata": {},
   "source": [
    "# SGD Note Serial Number OCR\n",
    "\n",
    "<em>Author: Loh Zhi Shen<br>   \n",
    "Date of revision: 4 March 2022</em>\n",
    "\n",
    "---\n",
    "\n",
    "<p>\n",
    "In this notebook, I attempt to create a computer vision pipeline to OCR the serial number of \\$2, \\$5, \\$10 and \\$50 Singapore notes. Each note has its serial number printed in 2 different places:\n",
    <br>
    "1. the bottom left corner - horizontally printed\n",
    "2. the right side of the image - vertically printed\n",
    <br>
    "I will be OCR'ing the vertical serial number as I deem it to be more challenging then the other as tesseract works better OCR'ing horizontally printed words.\n",
    "</p>\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577bff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# command line argument parsing\n",
    "import argparse\n",
    "# numeric processing\n",
    "import numpy as np\n",
    "# basic image preprocessing routines\n",
    "import cv2\n",
    "# OCR library\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c252f6",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "<strong>Resizing images:</strong>\n",
    "\n",
    "<p>\n",
    "There are 2 different ways to resize images:\n",
    "    \n",
    "1. forcing the image into a certain width and height by distorting the image\n",
    "2. resizing the image while maintaining the aspect ratio\n",
    "    \n",
    "Because distorting the serial image by forcing a size onto the image will make it harder for our tesseract model to OCR the characters, I will be using the second method to resize images.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012eec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, width = None, height = None, maintain_aspect = True):\n",
    "    if maintain_aspect:\n",
    "        if width and height:\n",
    "            raise ValueError(\"provide either width or height and not both when using maintain_aspect.\")\n",
    "        h, w, _ = image.shape\n",
    "        if width:\n",
    "            r = width / w\n",
    "        else:\n",
    "            r = height / w\n",
    "        new_h, new_w = int(h * r), int(w * r)\n",
    "        return cv2.resize(image, (new_w, new_h), interpolation = cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        if not width or not height:\n",
    "            raise ValueError(\"provide both width and height when not using maintain_aspect.\")\n",
    "        return cv2.resize(image, (width, height), interpolation = cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df409061",
   "metadata": {},
   "source": [
    "<strong>Sorting contours:</strong>\n",
    "\n",
    "<p>\n",
    "When sorting contours, the value that represents the contour depends on which axis and which direction we sort the contours in.\n",
    "    \n",
    "When sorting from left to right, we use the minimum x value for the contour whereas when sorting from right to left, we use the maximum.\n",
    "    \n",
    "Similarly, when sorting from top to bottom, we use the minimum y value for the contour and when sorting from bottom to the top, we use the maximum y value.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed27041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxXY(contour, horizontal = True, maximum = False):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    M = [[x, x + w], \n",
    "         [y, y + h]]\n",
    "    i = 0 if horizontal else 1\n",
    "    j = 1 if maximum else 0\n",
    "    return M[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34768294",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<strong>DO NOT RUN</strong>\n",
    "\n",
    "The following box of code is meant for running the program from command line and not from jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea879b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation of command line argument passing\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required = True, \n",
    "                help = \"name of the photo in the adjacent Images folder\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4b73f",
   "metadata": {},
   "source": [
    "## Start of program\n",
    "\n",
    "To replace the functionality of taking commandline inputs, I will be creating a dictionary of hardcoded commandline inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99aef9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcode any commandline inputs into the following dictionary\n",
    "args = {\"image\": \"SGD5.jpg\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad76cd4",
   "metadata": {},
   "source": [
    "### Loading image\n",
    "\n",
    "I will be using opencv for basic image preprocessing so the <i>\"cv2.imread\"</i> function will load our image into memory. \n",
    "\n",
    "Then, to make it easier to work with, I will scale the image down to a resonable size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17b8b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image into memory\n",
    "image = cv2.imread(\"Images/\" + args[\"image\"])\n",
    "\n",
    "# scale down the image to reduce computational requirements\n",
    "image = resize(image, height = 1000)\n",
    "\n",
    "# display the image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0122114f",
   "metadata": {},
   "source": [
    "### Basic Preprocessing\n",
    "\n",
    "A basic image preprocessing routine is used here.\n",
    "\n",
    "1. Converting the image to grayscale in preparation for thresholding\n",
    "2. Blurring the image to reduce noise\n",
    "3. OTSU thresholding to convert the image into a binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed414f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to gray scale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# blurring the image\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "\n",
    "# apply OTSU thresholding\n",
    "_, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "# display the image\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a782f6",
   "metadata": {},
   "source": [
    "### Locating ROI\n",
    "\n",
    "An assumption that I am making here is that the serial number is:\n",
    "\n",
    "1. a vertical column \n",
    "2. is on the right side of the note\n",
    "\n",
    "As such, I use a kernel with a much higher height then width and will sort the contours from right to left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0665ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kernels to identify ROI\n",
    "col_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 15))\n",
    "\n",
    "# apply morphological operations\n",
    "opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, col_kernel)\n",
    "\n",
    "# display the image\n",
    "cv2.imshow(\"Opened\", opened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e14668be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get contours\n",
    "contours, _ = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# order the contours from right to left\n",
    "contours = sorted(contours, key = lambda x: minMaxXY(x, maximum = True), reverse = True)\n",
    "\n",
    "# select the ROI\n",
    "roi = None\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    \n",
    "    if w > 10 and w < 50 and h > 100:\n",
    "        roi = cnt\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b7cc8",
   "metadata": {},
   "source": [
    "### Cleaning up the ROI\n",
    "\n",
    "As tesseract doesn't handle OCR'ing images when the characters are too close to the boundaries of the image, when cropping to the ROI, I added some padding around the region.\n",
    "\n",
    "Moreover, after cropping the image, there is a need to tidy it up due to the noise so I used some basic image processing tools to remove some of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fe8ae7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crop to ROI\n",
    "x,y,w,h = cv2.boundingRect(roi)\n",
    "padX = int(w * 0.2)\n",
    "padY = int(h * 0.01)\n",
    "crop = blur[max(0, y - padY // 2) : min(image.shape[0], y + h + padY // 2), \n",
    "            max(0, x - padX // 2): min(image.shape[1], x + w + padX // 2)]\n",
    "\n",
    "# Get structuring element\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "\n",
    "# Opening\n",
    "opened = cv2.morphologyEx(crop, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# OTSU thresholding\n",
    "_, output = cv2.threshold(opened, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "# Display the output\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ea93f",
   "metadata": {},
   "source": [
    "### OCR using Tesseract\n",
    "\n",
    "From some trial and error, I've found that page segmentation mode(psm) 6 works the best for images like this.\n",
    "\n",
    "Moreover, since the serial number can only contain alphanumerical characters, I created a whitelist to allow only alphanumerical characters.\n",
    "\n",
    "Similarly, I noticed that tesseract seems to be unable to recognise the '1' in the serial number so I added '|' to the white list as it is visually more similar to the font used in the serial number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "51ce7077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2FC629010\n"
     ]
    }
   ],
   "source": [
    "# Set config file\n",
    "config = \"--psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ|\"\n",
    "\n",
    "# OCR\n",
    "text = pytesseract.image_to_string(output, config = config).replace(\"\\n\", \"\").replace(\"|\", \"1\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa5243",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<b>Outcomes:</b>\n",
    "\n",
    "    \n",
    "When the program is ran with the $2 SGD note, tesseract outputs \"4HJ838350\" which is the same as the actual serial number of the note.\n",
    "\n",
    "When the program is ran with the $5 SGD note, tesseract outputs \"2FC629010\" which is almost identical to the actual serial number of the note expect that \"0\" has become \"6\".\n",
    "    \n",
    "When the program is ran with the $10 SGD note, tesseract outputs \"6FU269629\" which is the same as the actual serial number of the note.\n",
    "\n",
    "When the program is ran with the $50 SGD note, tesseract outputs \"5LE220174\" which is almost the same as the actual serial number except that the 'LI' should have been an 'M'.\n",
    "\n",
    "<b>Conclusion:</b>\n",
    "\n",
    "Overall, although the pipeline doesn't produce 100% accuracy, I feel that it is still accurate enough to the point that a simple checksum on the serial number could be used to identify mistakes made in the OCR process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370b864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
